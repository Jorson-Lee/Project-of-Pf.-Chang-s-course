{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"webcam_detection.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPEAZRdg3lIm+T4HD6lxK5G"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import os, sys\n","module_path = os.path.abspath(os.path.join('.'))\n","sys.path.append(module_path)\n","\n","from keras.models import Sequential\n","from keras.layers.core import Flatten, Dense, Dropout\n","from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n","from tensorflow.keras.optimizers import SGD\n","import cv2, numpy as np\n","\n","from keras import backend as K\n","#K.set_image_dim_ordering('th')\n","K.set_image_data_format('channels_first')\n","\n","\n","def VGG_16(weights_path=None, shape=(48, 48)):\n","    model = Sequential()\n","    model.add(ZeroPadding2D((1,1), input_shape=(1, 48, 48)))\n","    model.add(Convolution2D(32, 3, 3, activation='relu'))\n","    model.add(ZeroPadding2D((1,1)))\n","    model.add(Convolution2D(32, 3, 3, activation='relu'))\n","    model.add(MaxPooling2D((2,2), strides=(2,2)))\n","\n","    model.add(ZeroPadding2D((1,1)))\n","    model.add(Convolution2D(64, 3, 3, activation='relu'))\n","    model.add(ZeroPadding2D((1,1)))\n","    model.add(Convolution2D(64, 3, 3, activation='relu'))\n","    model.add(MaxPooling2D((2,2), strides=(2,2)))\n","\n","    model.add(ZeroPadding2D((1,1)))\n","    model.add(Convolution2D(128, 3, 3, activation='relu'))\n","    model.add(ZeroPadding2D((1,1)))\n","    model.add(Convolution2D(128, 3, 3, activation='relu'))\n","    model.add(ZeroPadding2D((1,1)))\n","    model.add(Convolution2D(128, 3, 3, activation='relu'))\n","    model.add(MaxPooling2D((2,2), strides=(2,2)))\n","\n","    '''\n","    model.add(ZeroPadding2D((1,1)))\n","    model.add(Convolution2D(512, 3, 3, activation='relu'))\n","    model.add(ZeroPadding2D((1,1)))\n","    model.add(Convolution2D(512, 3, 3, activation='relu'))\n","    model.add(ZeroPadding2D((1,1)))\n","    model.add(Convolution2D(512, 3, 3, activation='relu'))\n","    model.add(MaxPooling2D((2,2), strides=(2,2)))\n","\n","    model.add(ZeroPadding2D((1,1)))\n","    model.add(Convolution2D(512, 3, 3, activation='relu'))\n","    model.add(ZeroPadding2D((1,1)))\n","    model.add(Convolution2D(512, 3, 3, activation='relu'))\n","    model.add(ZeroPadding2D((1,1)))\n","    model.add(Convolution2D(512, 3, 3, activation='relu'))\n","    model.add(MaxPooling2D((2,2), strides=(2,2)))\n","    '''\n","    \n","    model.add(Flatten())\n","    model.add(Dense(1024, activation='relu'))\n","    model.add(Dropout(0.5))\n","    model.add(Dense(512, activation='relu'))\n","    model.add(Dropout(0.5))\n","    model.add(Dense(6, activation='softmax'))\n","    \n","    print (\"Create model successfully\")\n","    if weights_path:\n","        model.load_weights(weights_path)\n","\n","    model.compile(optimizer='adam', loss='categorical_crossentropy', \\\n","        metrics=['accuracy'])\n","\n","    return model"],"metadata":{"id":"ogTSyHb0kyuS","executionInfo":{"status":"ok","timestamp":1640066972202,"user_tz":-480,"elapsed":299,"user":{"displayName":"AP28_许儒怡","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17244627543529180816"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","\n","CASCADE_PATH = \"haarcascade_frontalface_default.xml\"\n","\n","RESIZE_SCALE = 3\n","REC_COLOR = (0, 255, 0)\n","\n","def getFaceCoordinates(image):\n","    cascade = cv2.CascadeClassifier(CASCADE_PATH)\n","    \n","    img_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","    img_gray = cv2.equalizeHist(img_gray)\n","    rects = cascade.detectMultiScale(\n","        img_gray,\n","        scaleFactor=1.1,\n","        minNeighbors=3,\n","        minSize=(48, 48)\n","        )\n","\n","    # For now, we only deal with the case that we detect one face.\n","    if(len(rects) != 1) :\n","        return None\n","    \n","    face = rects[0]\n","    bounding_box = [face[0], face[1], face[0] + face[2], face[1] + face[3]]\n","\n","    # return map((lambda x: x), bounding_box)\n","    return bounding_box\n","\n","def drawFace(img, faceCoordinates):\n","    cv2.rectangle(np.asarray(img), (faceCoordinates[0], faceCoordinates[1]), \\\n","    (faceCoordinates[2], faceCoordinates[3]), REC_COLOR, thickness=2)\n","\n","def crop_face(img, faceCoordinates):\n","    '''\n","    extend_len_x =  (256 - (faceCoordinates[3] - faceCoordinates[1]))/2\n","    extend_len_y =  (256 - (faceCoordinates[0] - faceCoordinates[2]))/2\n","    img_size = img.shape\n","    if (faceCoordinates[1] - extend_len_x) >= 0 :\n","        faceCoordinates[1] -= extend_len_x\n","    if (faceCoordinates[3] + extend_len_x) < img_size[0]:\n","        faceCoordinates[3] += extend_len_x\n","    if (faceCoordinates[0] - extend_len_y) >= 0 :\n","        faceCoordinates[0] -= extend_len_y\n","    if (faceCoordinates[2] + extend_len_y) < img_size[1]:\n","        faceCoordinates[2] += extend_len_y\n","    '''\n","    return img[faceCoordinates[1]:faceCoordinates[3], faceCoordinates[0]:faceCoordinates[2]]\n","\n","def preprocess(img, faceCoordinates, face_shape=(48, 48)):\n","    '''\n","        This function will crop user's face from the original frame\n","    '''\n","    face = crop_face(img, faceCoordinates)\n","    #face = img\n","    face_scaled = cv2.resize(face, face_shape)\n","    face_gray = cv2.cvtColor(face_scaled, cv2.COLOR_BGR2GRAY)\n","    \n","    return face_gray"],"metadata":{"id":"CvhY0GnqkiqA","executionInfo":{"status":"ok","timestamp":1640066976908,"user_tz":-480,"elapsed":289,"user":{"displayName":"AP28_许儒怡","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17244627543529180816"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","execution_count":11,"metadata":{"id":"LCVKVh8UkI_A","colab":{"base_uri":"https://localhost:8080/","height":378},"executionInfo":{"status":"error","timestamp":1640067532127,"user_tz":-480,"elapsed":476,"user":{"displayName":"AP28_许儒怡","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17244627543529180816"}},"outputId":"1158b471-479d-4260-bb4e-0af7dfc0a5a0"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-b53bd8290319>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mface_detection_utilities\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyVGG\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mvgg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'face_detection_utilities'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["import argparse\n","import sys, os\n","sys.path.append(\"../\")\n","\n","import cv2\n","import numpy as np\n","\n","import face_detection_utilities as fdu\n","\n","import model.myVGG as vgg\n","\n","windowsName = 'Preview Screen'\n","\n","parser = argparse.ArgumentParser(description='A live emotion recognition from webcam')\n","parser.add_argument('-testImage', help=('Given the path of testing image, the program will predict the result of the image.'\n","\"This function is used to test if the model works well.\"))\n","\n","args = parser.parse_args()\n","FACE_SHAPE = (48, 48)\n","\n","model = vgg.VGG_16('my_model_weights_83.h5')\n","#model = vgg.VGG_16()\n","\n","emo     = ['Angry', 'Fear', 'Happy',\n","           'Sad', 'Surprise', 'Neutral']\n","\n","def refreshFrame(frame, faceCoordinates):\n","    if faceCoordinates is not None:\n","        fdu.drawFace(frame, faceCoordinates)\n","    cv2.imshow(windowsName, frame)\n","\n","\n","def showScreenAndDectect(capture):\n","    while (True):\n","        flag, frame = capture.read()\n","        faceCoordinates = fdu.getFaceCoordinates(frame)\n","        refreshFrame(frame, faceCoordinates)\n","        \n","        if faceCoordinates is not None:\n","            face_img = fdu.preprocess(frame, faceCoordinates, face_shape=FACE_SHAPE)\n","            #cv2.imshow(windowsName, face_img)\n","\n","            input_img = np.expand_dims(face_img, axis=0)\n","            input_img = np.expand_dims(input_img, axis=0)\n","\n","            result = model.predict(input_img)[0]\n","            index = np.argmax(result)\n","            print (emo[index], 'prob:', max(result))\n","            # print(face_img.shape)\n","            # emotion = class_label[result_index]\n","            # print(emotion)\n","\n","def getCameraStreaming():\n","    capture = cv2.VideoCapture(0)\n","    if not capture:\n","        print(\"Failed to capture video streaming \")\n","        sys.exit(1)\n","    else:\n","        print(\"Successed to capture video streaming\")\n","        \n","    return capture\n","\n","def main():\n","    '''\n","    Arguments to be set:\n","        showCam : determine if show the camera preview screen.\n","    '''\n","    print(\"Enter main() function\")\n","    \n","    if args.testImage is not None:\n","        img = cv2.imread(args.testImage)\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","        img = cv2.resize(img, FACE_SHAPE)\n","        print(class_label[result[0]])\n","        sys.exit(0)\n","\n","    showCam = 1\n","\n","    capture = getCameraStreaming()\n","\n","    if showCam:\n","        cv2.startWindowThread()\n","        cv2.namedWindow(windowsName, cv2.WND_PROP_FULLSCREEN)\n","        cv2.setWindowProperty(windowsName, cv2.WND_PROP_FULLSCREEN, cv2.WND_PROP_FULLSCREEN)\n","    \n","    showScreenAndDectect(capture)\n","\n","if __name__ == '__main__':\n","    main()"]}]}