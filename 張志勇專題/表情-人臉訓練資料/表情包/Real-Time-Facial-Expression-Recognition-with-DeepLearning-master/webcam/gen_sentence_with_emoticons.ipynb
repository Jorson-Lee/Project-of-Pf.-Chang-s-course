{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"gen_sentence_with_emoticons.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMobx9ThNR9CuIPHUvr5uGV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"MjAmV76TjsNQ"},"outputs":[],"source":["import argparse\n","import sys, os\n","sys.path.append(\"../\")\n","\n","import cv2\n","import numpy as np\n","\n","import face_detection_utilities as fdu\n","\n","import model.myVGG as vgg\n","import speech_recognition as sr\n","\n","windowsName = 'Preview Screen'\n","\n","parser = argparse.ArgumentParser(description='A live emotion recognition from webcam')\n","\n","args = parser.parse_args()\n","FACE_SHAPE = (48, 48)\n","\n","model = vgg.VGG_16('my_model_weights_83.h5')\n","#model = vgg.VGG_16()\n","\n","emo     = ['Angry', 'Fear', 'Happy',\n","           'Sad', 'Surprise', 'Neutral']\n","\n","def speechRecognition():\n","    # obtain audio from the microphone \n","    print(\"Press 'y' to start~\")\n","    inputdata = input()\n","    if inputdata == 'y':\n","        inputdata = 0\n","        r = sr.Recognizer()\n","        with sr.Microphone() as source:\n","            print(\"Say something!\")\n","            audio = r.listen(source)\n","        # recognize speech using Google Speech Recognition\n","        try:\n","        # for testing purposes, we're just using the default API key\n","        # to use another API key, use `r.recognize_google(audio, key=\"GOOGLE_SPEECH_RECOGNITION_API_KEY\")`\n","        # instead of `r.recognize_google(audio)`\n","            recSuccess = 1\n","            recContent = r.recognize_google(audio)\n","            print(\"Speech Recognition thinks you said \" + recContent)#,language=\"cmn-Hant-TW\")\n","            return recContent\n","        except sr.UnknownValueError:\n","            print(\"Could not understand audio\")\n","        except sr.RequestError as e:\n","            print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))\n","\n","def refreshFrame(frame, faceCoordinates):\n","    if faceCoordinates is not None:\n","        fdu.drawFace(frame, faceCoordinates)\n","    cv2.imshow(windowsName, frame)\n","\n","\n","def showScreenAndDectect(capture):\n","    print(\"Face dececting...\")\n","    cnt = 5;\n","    while cnt:\n","        flag, frame = capture.read()\n","        faceCoordinates = fdu.getFaceCoordinates(frame)\n","        refreshFrame(frame, faceCoordinates)\n","        \n","        if faceCoordinates is not None:\n","            cnt -= 1\n","            face_img = fdu.preprocess(frame, faceCoordinates, face_shape=FACE_SHAPE)\n","            #cv2.imshow(windowsName, face_img)\n","\n","            input_img = np.expand_dims(face_img, axis=0)\n","            input_img = np.expand_dims(input_img, axis=0)\n","\n","            result = model.predict(input_img)[0]\n","            if cnt == 4:\n","                tot_result = result\n","            else:\n","                tot_result += result\n","            index = np.argmax(result)\n","            print ('Frame',5-cnt,':', emo[index], 'prob:', max(result))\n","            #index = np.argmax(result)\n","            #print (emo[index], 'prob:', max(result))\n","            # print(face_img.shape)\n","            # emotion = class_label[result_index]\n","            # print(emotion)\n","    index = np.argmax(tot_result)\n","    print ('Final decision:',emo[index], 'prob:', max(tot_result))\n","    return emo[index]\n","\n","def getCameraStreaming():\n","    capture = cv2.VideoCapture(0)\n","    if not capture:\n","        print(\"Failed to capture video streaming \")\n","        sys.exit(1)\n","    else:\n","        print(\"Successed to capture video streaming\")\n","        \n","    return capture\n","\n","def main():\n","    '''\n","    Arguments to be set:\n","        showCam : determine if show the camera preview screen.\n","    '''\n","    print(\"Enter main() function\")\n","    \n","    capture = getCameraStreaming()\n","\n","    cv2.startWindowThread()\n","    cv2.namedWindow(windowsName, cv2.WND_PROP_FULLSCREEN)\n","    cv2.setWindowProperty(windowsName, cv2.WND_PROP_FULLSCREEN, cv2.WND_PROP_FULLSCREEN)\n","    \n","    while True:\n","        recContent = speechRecognition()\n","        if recContent is not None:\n","            emotion = showScreenAndDectect(capture)\n","            if emotion == \"Angry\":\n","                emoji = \" >:O\"\n","            elif emotion == \"Fear\":\n","                emoji = \" :-S\"\n","            elif emotion == \"Happy\":\n","                emoji = \" :-D\"\n","            elif emotion == \"Sad\":\n","                emoji = \" :'(\"\n","            elif emotion == \"Surprise\":\n","                emoji = \" :-O\"\n","            else:\n","                emoji = \" \"\n","            print(\"Output result: \" + recContent + emoji)\n","\n","if __name__ == '__main__':\n","    main()"]}]}