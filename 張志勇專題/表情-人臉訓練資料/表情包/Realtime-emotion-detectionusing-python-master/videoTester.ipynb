{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"videoTester.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPi8u6yzhh1H3UApY2Rry2x"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":385},"id":"sBfZi0p-KbrD","executionInfo":{"status":"error","timestamp":1640081060113,"user_tz":-480,"elapsed":383,"user":{"displayName":"AP28_许儒怡","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17244627543529180816"}},"outputId":"5b2fddae-d54e-4830-ba98-3b9f8f368241"},"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-d07e2ef895a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mtest_img\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtake_photo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# captures frame and returns boolean value and captured image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mgray_img\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-12-d07e2ef895a4>\u001b[0m in \u001b[0;36mtake_photo\u001b[0;34m(filename, quality, size)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtake_photo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'photo.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m800\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHTML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVIDEO_HTML\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mquality\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdisplay_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'videoHTML'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m   \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_js\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m   \u001b[0mbinary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb64decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import os\n","import cv2\n","import numpy as np\n","from keras.models import model_from_json\n","from keras.preprocessing import image\n","\n","from IPython.display import display, Javascript\n","from google.colab.output import eval_js\n","from base64 import b64decode\n","\n","from IPython.display import HTML, Audio\n","\n","import matplotlib.pyplot as plt\n","from google.colab.patches import cv2_imshow\n","from google.colab.output import eval_js\n","from base64 import b64decode\n","import numpy as np\n","import io\n","from PIL import Image\n","\n","VIDEO_HTML = \"\"\"\n","<video autoplay\n"," width=%d height=%d style='cursor: pointer;'></video>\n","<script>\n","\n","var video = document.querySelector('video')\n","\n","navigator.mediaDevices.getUserMedia({ video: true })\n","  .then(stream=> video.srcObject = stream)\n","  \n","var data = new Promise(resolve=>{\n","  video.onclick = ()=>{\n","    var canvas = document.createElement('canvas')\n","    var [w,h] =[video.offsetWidth, video.offsetHeight]\n","    canvas.width = w\n","    canvas.height = h\n","    canvas.getContext('2d')\n","          .drawImage(video, 0, 0, w, h)\n","    video.srcObject.getVideoTracks()[0].stop()\n","    video.replaceWith(canvas)\n","    resolve(canvas.toDataURL('image/jpeg', %f))\n","  }\n","})\n","</script>\n","\"\"\"\n","def take_photo(filename='photo.jpg', quality=0.8, size=(800,600)):\n","  display(HTML(VIDEO_HTML % (size[0],size[1],quality)),display_id='videoHTML')\n","  data = eval_js(\"data\")\n","  binary = b64decode(data.split(',')[1])\n","  f = io.BytesIO(binary)\n","  return np.asarray(Image.open(f))\n","\n","\n","\n","\n","#load model\n","#model = model_from_json(open(\"fer.json\", \"r\").read())\n","#load weights\n","#model.load_weights('fer.h5')\n","\n","\n","face_haar_cascade = cv2.CascadeClassifier(cv2.data.haarcascades +'haarcascade_frontalface_default.xml')\n","\n","\n","cap=cv2.VideoCapture(0)\n","\n","while True:\n","    test_img=take_photo()# captures frame and returns boolean value and captured image\n","    \n","    gray_img= cv2.cvtColor(test_img, cv2.COLOR_BGR2GRAY)\n","\n","    faces_detected = face_haar_cascade.detectMultiScale(gray_img, 1.32, 5)\n","\n","\n","\n","    for (x,y,w,h) in faces_detected:\n","        cv2.rectangle(test_img,(x,y),(x+w,y+h),(255,0,0),thickness=7)\n","    #    roi_gray=gray_img[y:y+w,x:x+h]#cropping region of interest i.e. face area from  image\n","    #    roi_gray=cv2.resize(roi_gray,(48,48))\n","    #    img_pixels = image.img_to_array(roi_gray)\n","    #    img_pixels = np.expand_dims(img_pixels, axis = 0)\n","     #   img_pixels /= 255\n","\n","    #    predictions = model.predict(img_pixels)\n","\n","        #find max indexed array\n","    #    max_index = np.argmax(predictions[0])\n","\n","     #   emotions = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n","     #   predicted_emotion = emotions[max_index]\n","\n","    #    cv2.putText(test_img, predicted_emotion, (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n","\n","    resized_img = cv2.resize(test_img, (1000, 700))\n","    #cv2.imshow('Facial emotion analysis ',resized_img)\n","    plt.imshow(cv2.cvtColor(resized_img, cv2.COLOR_BGR2RGB))\n","    # as opencv loads in BGR format by default, we want to show it in RGB.\n","    plt.show()\n","\n","\n","    if cv2.waitKey(10) == ord('q'):#wait until 'q' key is pressed\n","        break\n","\n","cap.release()\n","cv2.destroyAllWindows\n"]}]}