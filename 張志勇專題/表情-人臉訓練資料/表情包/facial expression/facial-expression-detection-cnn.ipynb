{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"facial-expression-detection-cnn.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-06T07:32:04.671508Z","iopub.execute_input":"2021-11-06T07:32:04.671971Z","iopub.status.idle":"2021-11-06T07:32:04.707415Z","shell.execute_reply.started":"2021-11-06T07:32:04.671866Z","shell.execute_reply":"2021-11-06T07:32:04.706675Z"},"trusted":true,"id":"SmviKyUfdt9o","executionInfo":{"status":"error","timestamp":1639981079762,"user_tz":-480,"elapsed":11,"user":{"displayName":"AP28_许儒怡","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17244627543529180816"}},"outputId":"1dc5e2b2-46ed-442a-f330-7ca8a4594b4d","colab":{"base_uri":"https://localhost:8080/","height":240}},"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load in \n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the \"../input/\" directory.\n","# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n","\n","import os\n","print(os.listdir(\"../input/facial-expression/fer2013/\"))\n","\n","# Any results you write to the current directory are saved as output."],"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-24c9d2fa270d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../input/facial-expression/fer2013/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Any results you write to the current directory are saved as output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/facial-expression/fer2013/'"]}]},{"cell_type":"code","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"id":"9PlDRZT9dt9s"},"source":["import tensorflow as tf\n","\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n","from keras.layers import Dense, Activation, Dropout, Flatten\n","\n","from keras.preprocessing import image\n","from keras.preprocessing.image import ImageDataGenerator\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"_uuid":"87965c894d3b7f3b3dfc66d8c2a60efcc08a370d","trusted":true,"id":"0DpsZheEdt9t"},"source":["# get the data\n","filname = '../input/facial-expression/fer2013/fer2013.csv'\n","label_map = ['Anger', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n","names=['emotion','pixels','usage']\n","df=pd.read_csv('../input/facial-expression/fer2013/fer2013.csv',names=names, na_filter=False)\n","im=df['pixels']\n","df.head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"_uuid":"bfde4d91ff367dfa6764202c1b309ea291fb833a","trusted":true,"id":"VHyA_LVZdt9u"},"source":["def getData(filname):\n","    # images are 48x48\n","    # N = 35887\n","    Y = []\n","    X = []\n","    first = True\n","    for line in open(filname):\n","        if first:\n","            first = False\n","        else:\n","            row = line.split(',')\n","            Y.append(int(row[0]))\n","            X.append([int(p) for p in row[1].split()])\n","\n","    X, Y = np.array(X) / 255.0, np.array(Y)\n","    return X, Y\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"_uuid":"435d0e06553e3de3fd982e4a4a86c28018ac3913","trusted":true,"id":"pgE5UQqmdt9v"},"source":["X, Y = getData(filname)\n","num_class = len(set(Y))\n","print(num_class)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"_uuid":"f3c6bfb7aaf3c25ba7cdd5621e4d62b9eaa5502e","trusted":true,"id":"f4X7ZOrGdt9v"},"source":["# keras with tensorflow backend\n","N, D = X.shape\n","X = X.reshape(N, 48, 48, 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"_uuid":"be4faef86c3c5635697f10939547edd5c8760308","trusted":true,"id":"uN329W4vdt9w"},"source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=0)\n","y_train = (np.arange(num_class) == y_train[:, None]).astype(np.float32)\n","y_test = (np.arange(num_class) == y_test[:, None]).astype(np.float32)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"_uuid":"3afd36886a65ff49fe48ac73271f7477b574375a","trusted":true,"id":"h86gIkKLdt9x"},"source":["from keras.models import Sequential\n","from keras.layers import Dense , Activation , Dropout ,Flatten\n","from keras.layers.convolutional import Conv2D\n","from keras.layers.convolutional import MaxPooling2D\n","from keras.metrics import categorical_accuracy\n","from keras.models import model_from_json\n","from keras.callbacks import ModelCheckpoint\n","from keras.optimizers import *\n","from keras.layers.normalization import BatchNormalization"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"_uuid":"c8eaecce539d06c983ed73142ac1484dbfa5e970","trusted":true,"id":"Ana1Iedtdt9x"},"source":["def my_model():\n","    model = Sequential()\n","    input_shape = (48,48,1)\n","    model.add(Conv2D(64, (5, 5), input_shape=input_shape,activation='relu', padding='same'))\n","    model.add(Conv2D(64, (5, 5), activation='relu', padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","    model.add(Conv2D(128, (5, 5),activation='relu',padding='same'))\n","    model.add(Conv2D(128, (5, 5),activation='relu',padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","    model.add(Conv2D(256, (3, 3),activation='relu',padding='same'))\n","    model.add(Conv2D(256, (3, 3),activation='relu',padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","    model.add(Flatten())\n","    model.add(Dense(128))\n","    model.add(BatchNormalization())\n","    model.add(Activation('relu'))\n","    model.add(Dropout(0.2))\n","    model.add(Dense(7))\n","    model.add(Activation('softmax'))\n","    \n","    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='adam')\n","    # UNCOMMENT THIS TO VIEW THE ARCHITECTURE\n","    #model.summary()\n","    \n","    return model\n","model=my_model()\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"_uuid":"5004be413385dbdf6c3967d34c59e541095ea667","trusted":true,"id":"gQ9iQ8U5dt9z"},"source":["path_model='model_filter.h5' # save model at this location after each epoch\n","K.tensorflow_backend.clear_session() # destroys the current graph and builds a new one\n","model=my_model() # create the model\n","K.set_value(model.optimizer.lr,1e-3) # set the learning rate\n","# fit the model\n","h=model.fit(x=X_train,     \n","            y=y_train, \n","            batch_size=64, \n","            epochs=20, \n","            verbose=1, \n","            validation_data=(X_test,y_test),\n","            shuffle=True,\n","            callbacks=[\n","                ModelCheckpoint(filepath=path_model),\n","            ]\n","            )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"_uuid":"0c7e2abb2a89f4df0d28de0a49db1f60c84fbcf0","trusted":true,"id":"cqldFBeedt9z"},"source":["objects = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n","y_pos = np.arange(len(objects))\n","print(y_pos)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"_uuid":"077d44e8bbb7549a09682eb09c417903bf2fd935","trusted":true,"id":"hFr9ATOLdt90"},"source":["def emotion_analysis(emotions):\n","    objects = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']\n","    y_pos = np.arange(len(objects))\n","    plt.bar(y_pos, emotions, align='center', alpha=0.9)\n","    plt.tick_params(axis='x', which='both', pad=10,width=4,length=10)\n","    plt.xticks(y_pos, objects)\n","    plt.ylabel('percentage')\n","    plt.title('emotion')\n","    \n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"_uuid":"241291244491cc1e84a45ecb0da66c1c09a4cd7a","trusted":true,"id":"9vRPcRH5dt90"},"source":["y_pred=model.predict(X_test)\n","#print(y_pred)\n","y_test.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"_uuid":"0e97d2cb00640d2bfc4d4de9456249e893f72cc2","trusted":true,"id":"YGDMbA0Fdt91"},"source":["#import seaborn as sn\n","#import pandas as pd\n","#import matplotlib.pyplot as plt\n","#import numpy as np\n","#from sklearn.metrics import confusion_matrix\n","#%matplotlib inline\n","#cm = confusion_matrix(np.where(y_test == 1)[1], y_pred)\n","#cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","#df_cm = pd.DataFrame(cm, index = [i for i in \"0123456\"],\n","                  #columns = [i for i in \"0123456\"])\n","#plt.figure(figsize = (20,15))\n","#sn.heatmap(df_cm, annot=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NZqv7q1zdt91"},"source":["**Real Time Expression Prediction**"]},{"cell_type":"code","metadata":{"_uuid":"70fc48e66d18c54ba629e625ad8def5ad2d93fa6","trusted":true,"id":"mf5TENvpdt92","executionInfo":{"status":"error","timestamp":1640074799649,"user_tz":-480,"elapsed":978,"user":{"displayName":"AP28_许儒怡","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17244627543529180816"}},"outputId":"3ba46cc7-5936-4b05-ae25-8645122cedf5","colab":{"base_uri":"https://localhost:8080/","height":274}},"source":["from skimage import io\n","img = image.load_img('../input/myimage/Shawon.jpg', grayscale=True, target_size=(48, 48))\n","show_img=image.load_img('../input/myimage/Shawon.jpg', grayscale=False, target_size=(200, 200))\n","x = image.img_to_array(img)\n","x = np.expand_dims(x, axis = 0)\n","\n","x /= 255\n","\n","custom = model.predict(x)\n","#print(custom[0])\n","emotion_analysis(custom[0])\n","\n","x = np.array(x, 'float32')\n","x = x.reshape([48, 48]);\n","\n","plt.gray()\n","plt.imshow(show_img)\n","plt.show()\n","\n","m=0.000000000000000000001\n","a=custom[0]\n","for i in range(0,len(a)):\n","    if a[i]>m:\n","        m=a[i]\n","        ind=i\n","        \n","print('Expression Prediction:',objects[ind])\n","        "],"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-5924b00517cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/myimage/Shawon.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrayscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m48\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m48\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mshow_img\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/myimage/Shawon.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrayscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'image' is not defined"]}]},{"cell_type":"code","metadata":{"_uuid":"82db72b60f80eb18474bf880369791cf346c9749","trusted":true,"id":"NC3Oo3wrdt93"},"source":["from skimage import io\n","img = image.load_img('../input/testimages/wallpaper2you_443897.jpg', grayscale=True, target_size=(48, 48))\n","show_img=image.load_img('../input/testimages/wallpaper2you_443897.jpg', grayscale=False, target_size=(200, 200))\n","x = image.img_to_array(img)\n","x = np.expand_dims(x, axis = 0)\n","\n","x /= 255\n","\n","custom = model.predict(x)\n","#print(custom[0])\n","emotion_analysis(custom[0])\n","\n","x = np.array(x, 'float32')\n","x = x.reshape([48, 48]);\n","\n","plt.gray()\n","plt.imshow(show_img)\n","plt.show()\n","\n","m=0.000000000000000000001\n","a=custom[0]\n","for i in range(0,len(a)):\n","    if a[i]>m:\n","        m=a[i]\n","        ind=i\n","        \n","print('Expression Prediction:',objects[ind])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gXCYnJ5cdt93"},"source":["**Live Demo of Production Level Project**\n","\n","[Facial Expression Detection Web App](https://faceai.herokuapp.com/)"]}]}